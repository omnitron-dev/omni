# rotif — система уведомлений на базе Redis

**rotif** – это TypeScript-библиотека для организации системы уведомлений с использованием Redis в качестве бекенда. Она предназначена для отправки и получения сообщений (уведомлений) между компонентами распределённой системы с высокой надежностью и гибкостью. Библиотека поддерживает два режима доставки сообщений – **Redis Streams** (потоки Redis) для надежной доставки с подтверждением (ack) и **Redis Pub/Sub** для простых широковещательных уведомлений в реальном времени. Кроме того, rotif предоставляет возможности отложенной доставки сообщений, автоматических повторных попыток (retry) при сбоях, ведения очереди «мертвых» сообщений (DLQ), дедупликации сообщений для семантики *exactly-once*, а также набор хуков (middleware) для расширения функциональности. Библиотека спроектирована для горизонтального масштабирования и устойчивой работы в продакшене, включая поддержку Redis Cluster.

## Общее описание и возможности

**rotif** решает задачу обмена событиями и уведомлениями между сервисами или модулями, используя Redis как высокопроизводительный брокер сообщений. Ключевые возможности библиотеки:

- **Публикация и подписка** на события через Redis Streams (с механизмом *consumer group* для масштабируемой конкурирующей обработки) или через Redis Pub/Sub (для случаев, где допустима потеря сообщений).
- **Отложенная доставка сообщений** – возможность задать задержку (delay) или точное время доставки сообщения.
- **Авто-повторы (retry)** при неудачной обработке – сообщения, обработка которых завершилась с ошибкой, могут автоматически перенаправляться на повторную обработку через заданные интервалы.
- **Dead Letter Queue (DLQ)** – специальная «очередь мертвых писем» для сообщений, которые не удалось обработать после всех попыток; позволяет не терять такие сообщения, а обрабатывать их отдельно.
- **Дедупликация и семантика *exactly-once*** – предотвращение повторной обработки дублирующихся сообщений, как на уровне одного процесса, так и глобально (с использованием Redis для хранения обработанных ID).
- **Middleware hooks (хуки)** – точки расширения, позволяющие выполнять дополнительный код до и после публикации или обработки сообщений, а также перехватывать ошибки.
- **Статистика подписок** – возможность получить статистические данные по каждой подписке (количество обработанных сообщений, количество ошибок, и т.д.) через метод `Subscription.stats()`.

Благодаря этим возможностям, rotif подходит для построения надежных систем обмена событиями: от простых нотификаций в реальном времени до элементов очередей задач с гарантиями доставки и повторного выполнения. Ниже приводится подробная документация по установке, настройке и использованию библиотеки.

## Установка и требования

Перед началом работы убедитесь, что выполнены следующие требования:

- **Node.js**: версия 14 или выше (библиотека написана на TypeScript и транслируется в современный JavaScript, совместимый с ES2020+).
- **TypeScript**: (необязательно) версия 4.x и выше для разработки с типизацией. Библиотека поставляется с включенными `.d.ts` определениями типов.
- **Redis**: версия 5.0 или выше. Для использования режима Streams требуется Redis ≥ 5.0 (Streams появились в Redis 5). Рекомендуется Redis 6.x или 7.x для полной поддержки всех команд (например, команды `XAUTOCLAIM` доступны начиная с 6.2). Библиотека также совместима с Redis 7+ и поддерживает работу в режиме Redis Cluster.
- **Соединение с Redis**: разверните экземпляр Redis-сервера (локально или в сети) и убедитесь, что можете к нему подключаться. Если вы планируете использовать Redis Streams в продакшене, настройте механизм персистенции (снимки RDB или AOF) для надежного хранения данных.

Установка библиотеки производится через npm:

```bash
npm install @omnitron-dev/rotif
```

Или с помощью Yarn:

```bash
yarn add @omnitron-dev/rotif
```

После установки вы можете импортировать `NotificationManager` в своем проекте:

```typescript
import { NotificationManager } from '@omnitron-dev/rotif';
```

Библиотека не требует дополнительных зависимостей, кроме клиента Redis. По умолчанию используется официальный клиент **node-redis** (v4+) для подключения к Redis через предоставленный URL. Optionally, rotif может использовать `ioredis` при работе с Redis Cluster (см. раздел про кластер). В минимальной конфигурации достаточно указать URL подключения к Redis.

## Конфигурация NotificationManager

Основной класс библиотеки – **NotificationManager**. Экземпляр этого класса управляет соединением с Redis, публикацией сообщений и фоновыми потоками для обработки подписок, отложенных сообщений и т.д. При создании `NotificationManager` вы можете указать ряд настроек в виде объекта опций конструктора:

```typescript
const manager = new NotificationManager({
  redisUrl: 'redis://localhost:6379/0',
  // ... другие опции конфигурации ...
});
```

Ниже перечислены основные параметры конфигурации `NotificationManager` и их назначение:

- **`redisUrl`** (`string`) – URL подключения к Redis. Поддерживается формат URI, включая указание хоста, порта, базы данных и пароля (например, `redis://:password@host:6379/0`). Этот параметр является основным для установления соединения. Если Redis работает в режиме Cluster, укажите URL одного из узлов кластера (библиотека автоматически перенаправит запросы по slot'ам) или используйте `redisUrls`/`nodes` (см. ниже).
- **`redisOptions`** (`object`, опционально) – альтернативно URL, вы можете передать объект настроек клиента Redis (например, объект конфигурации для `createClient` из `node-redis`). Это может быть полезно для указания деталей подключения (таймауты, TLS, и т.п.) или для передачи заранее созданного клиента:
  ```typescript
  const client = createClient({ url: 'redis://localhost:6379' });
  const manager = new NotificationManager({ client });
  ```
  Если передан `client`, параметр `redisUrl` игнорируется.
- **`useCluster`** (`boolean`, по умолчанию `false`) – флаг, указывающий на использование Redis в режиме Cluster. Если `true`, библиотека ожидает список узлов в `redisOptions` или корректный URL кластера. В режиме кластера rotif постарается корректно работать с потоками и pub/sub (см. раздел про кластер).
- **`groupName`** (`string`, опционально) – глобальное имя группы потребителей по умолчанию для всех подписок Streams. Если указано, при подписке на поток через Streams будет использоваться это имя группы (если группа не существует, она будет создана). В противном случае группу нужно указывать отдельно для каждой подписки (рекомендуется явное указание для прозрачности). Использование единой группы означает, что все экземпляры вашего приложения будут конкурирующими потребителями в рамках этой группы.
- **`consumerName`** (`string`, опционально) – имя consumer-а по умолчанию для текущего экземпляра приложения. Применяется при подписке на Streams. Должно быть уникальным для каждого процесса/инстанса, иначе два экземпляра с одним именем будут рассматриваться Redis как один consumer (что может привести к некорректному распределению сообщений). Если не указано, библиотека сгенерирует уникальное имя автоматически (например, на основе ID процесса или случайного UUID).
- **`retryAttempts`** (`number` или `number[]`, по умолчанию `0`) – настройка повторных попыток обработки. Может быть числом (количество повторных попыток после первой, например `retryAttempts: 3` значит всего 4 попытки: 1 основная + 3 ретрая) или массивом чисел, задающих интервалы (в миллисекундах) перед каждой попыткой. Например, `retryAttempts: [1000, 5000, 10000]` – первый повтор через 1 секунду, второй через 5 сек, третий через 10 сек. Если указано число, по умолчанию используется фиксированная задержка между повторами (см. `retryDelay`). Если `0` – повторные попытки отключены (сообщение при ошибке сразу попадёт в DLQ или просто будет считаться невыполненным).
- **`retryDelay`** (`number`, по умолчанию `5000`) – задержка (в мс) перед повторной попыткой обработки сообщения, если `retryAttempts` задан числом. Игнорируется, если `retryAttempts` указан как массив (в этом случае задержки берутся из массива).
- **`enableDLQ`** (`boolean`, по умолчанию `true`) – включение механизма Dead Letter Queue. Если `true`, после исчерпания всех попыток (retry) сообщение будет отправлено в специальный поток DLQ. Если `false`, сообщения после неудач просто помечаются как обработанные (или удаляются) без сохранения. Как правило, отключать DLQ не рекомендуется, т.к. это последняя возможность расследовать потерянные сообщения.
- **`dlqStreamName`** (`function | string`, по умолчанию добавляет суффикс `":DLQ"` к имени события) – определяет название потока (или канала) для DLQ. По умолчанию, для каждого события будет создан свой поток DLQ. Например, для события `"orderCreated"` DLQ-поток будет назван `"orderCreated:DLQ"`. Вы можете передать свою функцию генерации имени или строковый шаблон. Для кластерного окружения рекомендуется убедиться, что ключ DLQ попадает в тот же hash-slot, что и оригинальный поток (напр., через `{}` в имени).
- **`dedupStore`** (`"memory" | "redis" | false`, по умолчанию `false`) – включение дедупликации сообщений (семантика *exactly-once*). Если значение `"memory"`, библиотека будет хранить идентификаторы обработанных сообщений в памяти процесса (в пределах одного экземпляра) и отфильтровывать дубликаты. Если `"redis"`, то для хранения ID используется Redis (напр. в виде множества или Bloom filter), что позволяет учитывать дубликаты между разными экземплярами и гарантирвать exactly-once семантику глобально. Если `false` – дедупликация отключена (возможна повторная обработка при повторной доставке). Подробнее в разделе о дедупликации.
- **`dedupTTL`** (`number`, по умолчанию `86400` секунд = 24 часа) – время жизни записей дедупликации. Через указанный период ID обработанного сообщения будет удалён из хранилища дедупликации, после чего повторная доставка такого же ID снова будет обработана как новое сообщение. Эта опция предотвращает неограниченный рост памяти на хранение всех когда-либо обработанных сообщений. Настройте TTL в зависимости от требуемого окна exactly-once. Игнорируется, если `dedupStore` = false.
- **`delayProcessingInterval`** (`number`, по умолчанию `1000` мс) – период (интервал) проверки отложенных сообщений. Библиотека использует внутренний таймер, который с заданным интервалом проверяет хранилище отложенных сообщений и публикует те, у которых наступило время доставки. Значение по умолчанию 1 секунда означает, что сообщение будет доставлено в течение ~1 секунды после наступления времени `deliverAt`. Можно уменьшить интервал для большей точности (с нагрузкой на Redis) или увеличить для экономии ресурсов.
- **`maxStreamLength`** (`number | "approx"`, опционально) – максимальная длина стрима при добавлении новых сообщений. Если указано число, библиотека будет вызывать `XADD ... MAXLEN` для обрезки (триммирования) потока примерно до этого количества записей (approximate trimming с `~`). Если указано `"approx"` вместе с числом, используется приблизительное обрезание, если просто число – точное обрезание. Например, `maxStreamLength: 10000` будет поддерживать длину каждого потока около 10k сообщений, удаляя старые записи. Будьте внимательны: обрезка потока пригодна, если у вас *одна* группа потребителей или все группы уже обработали старые сообщения. В противном случае не обрезайте сообщения, которые еще не были прочитаны нужными группами.
- **Параметры хуков (middleware)** – хуки можно передать как в конфигурации менеджера, так и добавлять/переопределять при подписке. Глобальные хуки:
  - `beforePublish(event, message)` – вызывается перед публикацией сообщения в Redis. Может использоваться для логирования или модификации сообщения. Если вернёт `false`, публикация отменится.
  - `afterPublish(event, message, messageId)` – вызывается после успешной отправки сообщения (возвращает `messageId` для Streams или `number` получателей для Pub/Sub). Используется для логирования, метрик и пр.
  - `beforeProcess(event, message)` – глобальный хук перед обработкой сообщения подписчиком. Вызывается **до** пользовательского обработчика. Может, например, трассировать начало обработки.
  - `afterProcess(event, message)` – глобальный хук после успешной обработки сообщения (после выполнения обработчика и ack). Можно использовать для сбора метрик по времени обработки.
  - `onError(event, message, error)` – глобальный обработчик ошибок, возникающих при обработке сообщения. Вызывается перед логикой retry/DLQ. Можно залогировать ошибку или метрику. Если `onError` вернёт `false`, библиотека **не будет** выполнять стандартный механизм retry/DLQ для данного сообщения (считается, что ошибка обработана вручную).

  Эти же хуки можно указывать и на уровне конкретной подписки (см. ниже), чтобы применить их только к определённому событию. Локальные (переписывают глобальные) хуки передаются через опции при вызове `subscribe()`.

Это далеко не полный перечень настроек – **NotificationManager** также может принимать другие опции клиента Redis (например, опции TLS, время блокировки чтения и т.д.) через `redisOptions`. Приведённые выше – основные, используемые для управления поведением библиотеки. Ниже мы рассмотрим применение этих настроек на практике.

## Использование: публикация и подписка

rotif позволяет создавать *издателей* и *подписчиков* уведомлений с минимальным кодом. Основные методы: `publish()` для отправки сообщения и `subscribe()` для прослушивания сообщений. Оба метода работают как с механизмом Streams, так и с Pub/Sub.

### Публикация сообщения

Метод `publish(event, payload, options?)` отправляет новое сообщение (уведомление) о событии. Параметры:
- `event` (`string`): название события/канала. Например, `"user.registered"` или `"orderCreated"`. Это имя будет использоваться как ключ Redis: либо название Redis Stream, либо название канала Pub/Sub.
- `payload` (`any`): данные сообщения. Любой сериализуемый объект. Библиотека автоматически сериализует сообщение (по умолчанию в JSON) перед отправкой и десериализует на стороне получателя. Данные могут включать, например, идентификатор пользователя, детали заказа и т.п.
- `options` (`object`, необязательно): дополнительные опции для конкретного сообщения:
  - `deliverAt` (`Date` или `number`) – отложенная доставка: абсолютное время, когда сообщение должно быть доставлено подписчикам. Можно передать объект Date или таймстамп (UTC мс). Если указано `deliverAt` в будущем, сообщение до наступления этого времени хранится в специальном отложенном списке в Redis и будет отправлено только когда текущее время превысит заданное.
  - `delayMs` (`number`) – отложенная доставка: относительная задержка в миллисекундах. Например, `delayMs: 5000` отправит сообщение через 5 секунд. `delayMs` – сахар для `deliverAt = Date.now() + delayMs`.
  - `dedupKey` (`string`) – ключ дедупликации сообщения. Если указан и включена дедупликация (`dedupStore`), то библиотека пометит это сообщение данным ключом. Повторные публикации с тем же `dedupKey` могут быть отброшены (точное поведение зависит от режима дедупликации, см. раздел о dedup). Например, можно использовать уникальный ID события, чтобы предотвратить обработку дубликатов.
  - `pubsub` (`boolean`) – принудительная отправка через Pub/Sub (игнорируя Streams). По умолчанию, если существуют подписчики через Streams (с группами) для данного события, сообщение будет добавлено в поток (Stream). Если же все подписки для события используют Pub/Sub или явно указан этот флаг, будет использован механизм публикации через `PUBLISH`. Обычно указывать не нужно – rotif сам определяет оптимальный способ доставки.
  - `headers` (`object`) – вспомогательные метаданные сообщения (например, контекст, тип и пр.). Они будут сохранены вместе с сообщением. В Streams эти метаданные хранятся как дополнительные поля записи, в Pub/Sub они могут быть включены в полезную нагрузку. Обработка `headers` остаётся на стороне вашего приложения (например, вы можете передать trace-id для распределённой трассировки).

Пример – отправим простое уведомление о регистрации пользователя:

```typescript
await manager.publish('user.registered', { userId: 123, name: 'Alice' });
```

Этот вызов сразу запишет сообщение в Redis. Если на событие `"user.registered"` кто-то подписан:
- Через **Streams** (при наличии группы потребителей) – сообщение попадёт в Stream с именем `"user.registered"` и станет доступно для чтения подписчиками из группы.
- Через **Pub/Sub** – сообщение отправится по каналу `"user.registered"` всем текущим подписчикам.

Если подписчиков нет, поведение различается:
- В случае **Streams** сообщение останется в потоке до тех пор, пока не будет прочитано (или удалено/обрезано администратором). Это позволяет подписчикам подключиться позже и получить даже ранее отправленные сообщения (если их группа настроена на чтение с начала или стрим не обрезан).
- В случае **Pub/Sub** сообщение просто не будет получено никем (если на момент публикации не было активных подписчиков). Такие сообщения не сохраняются – это особенность Redis Pub/Sub.

**Выбор механизма Streams vs Pub/Sub:**  
По умолчанию rotif предпочитает **Streams**, так как они обеспечивают надежную доставку (хотя и с чуть большей задержкой) и гарантии. Если вы вызываете `subscribe()` указывая `group` (название группы) – вы создаёте подписчика на Stream. Если вызываете `subscribe()` без группы (или явно с опцией `{ pubsub: true }`), то используете Pub/Sub. Обычно для критичных событий (финансовые транзакции, изменения состояния системы) выбирают Streams, для не критичных или второстепенных – Pub/Sub. Вы можете одновременно использовать оба подхода для разных событий в одном `NotificationManager`.

### Подписка на сообщения

Для получения уведомлений используется метод `subscribe(event, handler, options?)`. После его вызова библиотека начинает в фоновом режиме слушать указанный event/канал и при поступлении новых сообщений вызывать функцию-обработчик. Параметры:
- `event` (`string`): имя события (должно совпадать с именем, используемым при публикации).
- `handler` (`function`): функция обработчик сообщения, вызывается как `handler(message, context)`. Здесь `message` – распарсенное содержимое, переданное при публикации (`payload`), а `context` – дополнительная информация о сообщении:
  - `context.id` – идентификатор сообщения (строка Redis Stream ID, либо `null` для Pub/Sub, где у сообщений нет ID).
  - `context.attempt` – номер попытки обработки (счетчик retry; `1` для первой попытки, увеличивается при повторных).
  - `context.timestamp` – временная метка, когда сообщение было опубликовано.
  - `context.event` – название события.
  - `context.deduplicated` – флаг, показывающий было ли сообщение помечено как дубликат и пропущено (см. deduplication). Обычно `false` для обычной обработки, `true` если сообщение уже обрабатывалось ранее.
  - ... и др. (включая `headers`, если были заданы при публикации).
- `options` (`object`): настройки подписки:
  - `group` (`string`) – **обязателен для Streams**: имя группы потребителей. Если указано, подписка будет работать через Redis Streams с этой группой. Группа будет автоматически создана, если не существует (с начальной позицией `$`, т.е. получать только новые сообщения). Все подписчики, использующие одно и то же имя группы для данного `event`, образуют *consumer group* и будут совместно (конкурентно) обрабатывать поток сообщений, каждый получит свою часть. Если группа не указана и не включен `pubsub`, библиотека может использовать неявную группу по умолчанию (см. `groupName` в конфиге) или переключится в режим Pub/Sub.
  - `consumer` (`string`) – имя конкретного consumer-а в группе (для Streams). Если не указано, будет использовано глобальное значение `consumerName` из настроек или сгенерировано автоматически. В **каждом процессе** приложения имя consumer-а для одной группы должно быть уникальным, иначе Redis не различит их. Например, можно использовать hostname или ID инстанса. Consumer отвечает за отслеживание прочитанных/неподтвержденных сообщений внутри группы.
  - `pubsub` (`boolean`) – если `true`, явным образом устанавливает режим Pub/Sub для этой подписки, игнорируя группы. Используется, если вы хотите подписаться на канал Pub/Sub независимо от настроек групп. Если указано `pubsub: true`, параметры `group` и `consumer` игнорируются.
  - `manualAck` (`boolean`, по умолчанию `false`) – режим ручного подтверждения. По умолчанию для Streams библиотека автоматически отправляет подтверждение (`XACK`) после успешного выполнения вашего `handler`. Если включен manualAck, библиотека не будет автоматически подтверждать, и вам доступна функция `context.ack()` внутри обработчика для явного подтверждения. Этот режим полезен, если вы хотите подтверждать сообщения после выполнения каких-то асинхронных действий вне основного обработчика.
  - Локальные хуки: `beforeProcess`, `afterProcess`, `onError` – можно передать функции аналогично глобальным хукам, но они будут применяться **только** для данной подписки (переопределяя глобальные). Их сигнатуры такие же, но без параметра `event` (т.к. он известен):
    - `beforeProcess(message, context)`
    - `afterProcess(message, context)`
    - `onError(message, context, error)`
    - Например, можно передать `onError` для конкретной подписки, чтобы особым образом обрабатывать ошибки этого типа сообщений.

**Пример 1: подписка на события через Streams (надёжная доставка)**

```typescript
// Подписываемся на событие "order.created" с использованием группы "orderService"
manager.subscribe('order.created', async (order, ctx) => {
  console.log('Получен новый заказ:', order.id);
  try {
    // Обработка заказа...
    await processOrder(order);
    console.log('Заказ обработан успешно');
    // После возврата промиса или резолва, rotif автоматически выполнит XACK
  } catch (err) {
    console.error('Ошибка при обработке заказа:', err);
    throw err; // проброс ошибки сигнализирует rotif, что обработка не удалась
  }
}, { group: 'orderService', consumer: 'orderService-instance-1' });
```

В этом примере все экземпляры вашего приложения, подписанные на `"order.created"` с одной группой `"orderService"`, будут совместно получать заказы из одного потока:
- Сообщения распределяются между потребителями (конкурентно) внутри группы. Например, первый заказ может достаться экземпляру с consumer `"instance-1"`, второй – `"instance-2"`, и т.д.
- Если обработчик завершается без выброса ошибки (или возвращает успешно резолвленный промис), rotif отправляет подтверждение Redis (`XACK`), и сообщение считается обработанным.
- Если происходит ошибка (исключение/отклонение промиса), rotif **не подтверждает** сообщение и инициирует механизм **retry** (описан далее). Таким образом, сообщение останется в *Pending Entries List* группы и через заданное время будет повторно выдано (либо этому же consumer-у, либо другому, см. retry и zombie-consumers ниже).

**Пример 2: подписка через Pub/Sub (широковещательно, без подтверждений)**

```typescript
// Подписываемся на уведомления о входе пользователя через Pub/Sub
manager.subscribe('user.login', (info, ctx) => {
  console.log(`Пользователь ${info.userId} вошел в систему с IP ${info.ip}`);
  // Здесь даже если бросить ошибку, повторной доставки не будет (Pub/Sub at-most-once)
}, { pubsub: true });
```

В этом случае подписка осуществляется через Redis Pub/Sub:
- Все экземпляры, подписавшиеся на `"user.login"` с `pubsub: true`, будут получать *каждое* сообщение (в отличие от Streams, где сообщение в рамках группы идёт только одному потребителю). Это полезно для событий, которые каждый получатель должен обработать независимо (например, обновление кэша в разных сервисах, оповещение нескольких несвязанных систем и т.п.).
- Нет механизма подтверждения или повторной доставки: если обработчик упал или не успел, сообщение всё равно считается доставленным (semantics *at-most-once*). 
- Pub/Sub быстрее и потребляет меньше ресурсов Redis (нет хранения сообщений), но не гарантирует доставку если получатель был оффлайн или произошёл сбой во время обработки.

Вы можете вызывать `subscribe()` несколько раз для разных событий или даже для одного и того же события в разных местах программы. Метод `subscribe` возвращает объект **Subscription**, который представляет подписку и позволяет получить статистику, а также отписаться при необходимости. Например:

```typescript
const subscription = manager.subscribe('metrics.update', onMetrics, { group: 'metricsService' });
// ... позднее, если нужно остановить получение:
subscription.unsubscribe(); // закроет соединение/слушатель для этого события
```

> **Важно:** Если вы вызываете `subscribe()` без указания `group` **и** без `{ pubsub: true }`, библиотека решит способ подписки автоматически. Обычно, если для этого события уже создавалась группа (или задан `groupName`), подписка пойдёт через Streams (создав новую группу или используя существующую). Если же ни одной группы для события нет, будет использован Pub/Sub. Рекомендуется явно указывать `group` для критичных путей или `pubsub` для широковещательных, чтобы избежать двусмысленности. Не смешивайте в рамках одного события подписчиков Streams и Pub/Sub – хотя rotif поддерживает оба, логика доставки в этих режимах не синхронизирована между собой (т.е. `publish` не будет отправлять одно сообщение и в поток, и в канал автоматически).

## Отложенные сообщения (Scheduled Delivery)

Библиотека позволяет планировать доставку сообщения с задержкой или к определенному моменту времени. Это удобно для реализации отложенных уведомлений, напоминаний, или ретри с задержкой.

Чтобы отправить сообщение с задержкой, используйте опции `delayMs` или `deliverAt` при публикации:

```typescript
// Отправить уведомление "password.reset" через 1 час
await manager.publish('password.reset', { userId: 42, email: 'user@example.com' }, 
  { delayMs: 3600_000 });
// То же самое, указав конкретное время доставки (например, завтра 9:00)
const deliverTime = new Date();
deliverTime.setDate(deliverTime.getDate() + 1);
deliverTime.setHours(9, 0, 0, 0);
await manager.publish('password.reset', { userId: 42, email: 'user@example.com' }, 
  { deliverAt: deliverTime });
```

При использовании этих опций rotif **не сразу** доставляет сообщение подписчикам. Вместо этого оно сохраняется во временном хранилище (в Redis) до наступления заданного времени:
- Реализация: библиотека использует отсортированное множество (Redis Sorted Set) для хранения отложенных сообщений, где значение – содержание сообщения, а *score* – метка времени доставки. Внутренний таймер (`delayProcessingInterval`) периодически проверяет Redis на наличие сообщений со временем `<= сейчас` и переносит их в основной поток/канал.
- Когда наступает время доставки, сообщение автоматически публикуется как обычное (будто вызвали `publish` без задержки). Подписчики получат его в штатном порядке.

Преимущества такого подхода:
- Надежность: отложенные сообщения хранятся в Redis, и не пропадут при перезапуске приложения. Даже если приложение/NotificationManager перезапущены, новые экземпляры продолжат обработку отложенных сообщений (важно: при мульти-инстансовом развертывании убедитесь, что запущен только один таймер обработки задержек, либо используйте механизм *leader election* — в текущей версии rotif предполагается один активный instance для отложенных задач, чтобы не дублировать публикацию).
- Точность: можно довольно точно указать время. Задержка ограничена только точностью системных часов и интервалом опроса (по умолчанию шаг 1 сек).
- Гибкость: deliverAt позволяет указать конкретное время (например, *cron*-подобные сценарии: “отправить уведомление в полночь”), delayMs – проще для относительных задержек (“через N секунд”).

**Важно:** Отложенные сообщения на данный момент поддерживаются **только в режиме Streams.** Если вы публикуете с задержкой, даже для событий, на которые подписаны Pub/Sub получатели, библиотека воспользуется механизмом Streams, чтобы гарантировать хранение. Таким образом, подписчикам через Pub/Sub такие сообщения придут **только если** на то же событие есть хотя бы один подписчик Streams-группы (который получит сообщение из стрима и далее, возможно, вручную републикует в канал – подобного функционала сейчас нет). Проще: используйте delay только если подписчики работают через Streams. Если вам нужна отложенная широковещательная доставка – рассмотрите изменение архитектуры или используйте отдельный поток + подписчик, который потом выполнит PUBLISH.

rotif автоматически создаёт необходимое хранилище и обрабатывает его. Однако обратите внимание на нагрузку:
- Все отложенные сообщения хранятся в одном sorted set (`rotif:scheduled` по умолчанию, либо с префиксом, если указан). Количество элементов в нём равно количеству отложенных сообщений, не доставленных на текущий момент. Желательно чистить/ограничивать его, если планируются миллионы отложенных событий.
- Интервал опроса (`delayProcessingInterval`) можно настроить. Слишком частый опрос (например, 50-100 мс) увеличит нагрузку на Redis, слишком редкий (несколько секунд) – снизит точность времени доставки. 1 секунда – баланс между точностью и нагрузкой.
- В кластере Redis хранение отложенных событий можно поместить в отдельный узел (ключ `rotif:scheduled`), т.к. команда выборки (ZPOPMIN) не конфликтует с операциями над стримами.

## Повторные попытки (Retry)

Одно из ключевых преимуществ использования rotif (и Redis Streams) – встроенная поддержка повторных попыток обработки сообщений. В реальных системах обработка сообщения может завершиться неудачно: например, из-за временной ошибки сети или недоступности внешнего сервиса. Вместо того чтобы сразу признавать такое сообщение потерянным, rotif позволяет автоматически повторить попытку спустя некоторое время.

**Как это работает:**  
Когда подписчик обрабатывает сообщение в режиме Streams и выбрасывает ошибку (или возвращает отклонённый Promise), библиотека фиксирует неудачу:
- Сообщение **не подтверждается** (`XACK` не вызывается). Вследствие этого в Redis оно остаётся в списке *pending* для группы – т.е. помечено как доставленное consumer-у, но не обработанное.
- NotificationManager планирует повторную доставку. Интервал и количество повторов задаётся настройками `retryAttempts` и `retryDelay` в конфигурации.
- Через указанный промежуток rotif либо с помощью команды `XCLAIM`/`XAUTOCLAIM` забирает сообщение из pending обратно и передаёт на обработку снова, либо (проще) публикует новое сообщение с теми же данными. **В реализации rotif используется подход повторной выдачи pending сообщений**, что обеспечивает сохранение исходного идентификатора и истории попыток.
- Поле `context.attempt` в обработчике позволяет узнать номер текущей попытки. Первый вызов обработчика для сообщения – attempt = 1, при первом retry – 2 и т.д.
- Если сообщение успешно обработано на одной из повторных попыток, процесс останавливается: вызывается XACK и сообщение удаляется из pending.
- Если сообщение продолжает ошибаться и количество попыток достигло `retryAttempts` (например, 3 повтора), то дальнейшие попытки прекращаются. Такое сообщение считается безнадёжным и перемещается в **DLQ** (Dead Letter Queue), если она включена.

Настройки, влияющие на поведение:
- `retryAttempts`: сколько раз пробовать снова. Если это число 0, retry отключен (любая ошибка ведёт сразу к DLQ или потере). Если 1 – будет одна повторная попытка (итого 2 обработки максимум).
- `retryDelay`: фиксированная задержка перед **каждым** повтором, если `retryAttempts` число. Если массив – задержки между попытками могут различаться.
- Максимальное время ожидания перед повтором – суммарно определяется настройками. Например, `retryAttempts: [1000, 5000, 10000]` охватывает три повтора в течение ~16 секунд. Если приложение или Redis находятся в оффлайне в момент, когда должен был произойти retry, попытка выполнится как только сервис восстановится (т.е. задержка фактически может быть дольше запланированной, но не короче).

**Пример: обработка с автоматическим ретраем**

Допустим, у нас есть сервис, который отправляет электронные письма, и мы хотим, чтобы неудачная попытка отправки повторялась 2 раза с интервалом в 10 секунд:

```typescript
const manager = new NotificationManager({ retryAttempts: 2, retryDelay: 10000 });
manager.subscribe('email.send', async (payload) => {
  const { address, body } = payload;
  console.log(`Отправка письма на ${address}...`);
  await emailService.sendMail(address, body);
  console.log('Письмо отправлено успешно.');
}, { group: 'mailer' });
```

```typescript
// Публикуем задачу на отправку письма
await manager.publish('email.send', { address: 'user@example.com', body: 'Hello!' });
```

В этом примере, если `emailService.sendMail` выбросит ошибку (например, соединение SMTP не удалось):
- Первая попытка (attempt=1) неудачна, сообщение остаётся не подтвердённым.
- Через 10 секунд rotif автоматически выдаст сообщение снова тому же или другому свободному consumer-у группы "mailer". В логе будет вторая попытка.
- Если со второй попытки также получаем ошибку, через ещё 10 секунд будет третья, последняя попытка (retryAttempts = 2 означает 2 повтора + 1 оригинал = 3 попытки).
- В случае успеха на любой из попыток – мы выйдем из цикла ретраев.
- В случае неудачи на всех попытках – сообщение переместится в DLQ (подробнее далее).

**Замечания по реализации:**
- rotif отслеживает время, прошедшее с момента выдачи сообщения, через поле *Idle* (простой) в Redis Streams. Команда `XREADGROUP` может использоваться с параметром `BLOCK` (блокирующее чтение). В то же время, чтобы реализовать задержку перед повтором, библиотека использует `XAUTOCLAIM` (начиная с Redis 6.2) или `XCLAIM` для получения сообщений, находящихся в pending дольше заданного интервала. Проще говоря, сообщение, которое висит не подтверждённым дольше `retryDelay`, считается "просроченным" и передаётся заново.
- Каждая повторная доставка происходит с тем же `message.id` (если Streams) и с increment-ом поля `attempt` в контексте. То есть, вы можете логировать попытки и видеть, что, например, message ID `1656367412345-0` обработан с attempt=3.
- **Ограничение:** Retry работает только для механизма Streams. В режиме Pub/Sub, поскольку нет понятия pending и ack, библиотека **не может** повторно отправить сообщение автоматически. Если вам нужны повторы – используйте Streams. (Вы конечно можете в обработчике Pub/Sub самостоятельно вызвать повторную логику, но это вручную).

## Dead Letter Queue (DLQ)

**Dead Letter Queue** – это механизм отвода "необрабатываемых" сообщений. Если сообщение исчерпало все попытки обработки и так и не было успешно обработано, его можно направить в специальную очередь (или поток) для дальнейшего анализа, ручной обработки или повторной загрузки позже.

В rotif DLQ включён по умолчанию (`enableDLQ: true`). Как он работает:
- После последней неудачной попытки (например, 3-й retry, если вы задали 2 повтора), сообщение не подтверждается и больше не будет автоматически раздаваться подписчикам.
- Вместо этого NotificationManager выполняет публикацию этого сообщения в отдельный **DLQ-поток**. По умолчанию его имя – оригинальное имя события + суффикс `:DLQ`. Например, для события `"email.send"` DLQ-поток будет `"email.send:DLQ"`.
- Сообщение в DLQ обычно содержит те же данные, что и оригинальное, плюс некоторые метаданные о неудачной обработке (например, число попыток, причина ошибки). Формат может выглядеть так:
  ```json
  {
    "originalPayload": { ... }, 
    "error": "Description of last error",
    "attempts": 3,
    "timestamp": 1680000000000
  }
  ```
  (Конкретный формат зависит от реализации, но в целом полезно сохранить информацию о причине сбоя).
- DLQ-поток – это обычный Redis Stream. Вы можете подписаться на него так же, как на другие события, с помощью `subscribe`. Например:
  ```typescript
  manager.subscribe('email.send:DLQ', (msg) => {
    console.error('Сообщение попало в DLQ:', msg.error, msg.originalPayload);
    // Можно реализовать оповещение разработчиков, запись в особый лог, либо попытку особой обработки
  }, { group: 'dlqHandlers' });
  ```
  Таким образом, у вас может быть отдельный обработчик для "проваленных" сообщений.

**Важно:** обработка DLQ-сообщений – на ваше усмотрение. Библиотека лишь помещает их в поток. Вы можете:
- Просматривать их через `XREAD`/`XREADGROUP` инструментами redis-cli для ручного анализа.
- Автоматически мониторить и оповещать (например, отправлять алерт, если что-то оказалось в DLQ).
- Попытаться спустя время перезапустить обработку: например, переносить из DLQ обратно в основной поток или вызывать нужные действия вручную. (rotif не реализует автоматического *реигра* DLQ, т.к. это специфично для каждого случая).
- Очищать DLQ спустя какое-то время, если сообщения не критичны, чтобы не копить бесконечно (возможно, с помощью `XTRIM` или вручную).

Если вы не хотите пользоваться DLQ, можно отключить `enableDLQ`. В этом случае после последней неудачной попытки rotif просто выполнит `XACK` (чтобы убрать сообщение из pending) и *не* будет сохранять его. Вы потеряете это сообщение, о чём следует помнить.

Заметим, что DLQ применим только к режиму Streams (по тем же причинам, что и retry). В Pub/Sub нет ретраев, а значит и DLQ не формируется – сообщение просто будет упущено. Поэтому, если для вас важна гарантия не потерять ни одно сообщение, используйте Streams + DLQ.

## Exactly-once и дедупликация сообщений

По умолчанию, система на базе Redis Streams обеспечивает семантику **at-least-once**: каждое сообщение будет доставлено *как минимум одному* потребителю. Однако возможно, что при сбоях или повторах некоторые сообщения будут доставлены повторно тому же или другому потребителю (например, после рестарта приложения или при ручном переносе pending-сообщений). Чтобы избежать повторной обработки одних и тех же событий, rotif может применить **дедупликацию**.

Дедупликация – это фильтрация повторных сообщений по уникальному идентификатору, чтобы обработчик не выполнил работу дважды. В контексте rotif дедупликация позволяет достичь эффекта *exactly-once processing* – т.е. каждый логический "идемпотентный" идентификатор события будет обработан ровно один раз.

Механизмы дедупликации в rotif:
- **In-memory (в памяти)**: Когда включен режим `dedupStore: "memory"`, NotificationManager будет хранить в памяти (например, в `Set`) идентификаторы уже обработанных сообщений. Идентификатором может служить либо Redis Stream ID (который уникален для каждой записи в стриме), либо пользовательский `dedupKey`, указанный при публикации. При получении нового сообщения подписчик сначала проверяет: не содержится ли его ID/ключ в уже обработанных. Если содержится, сообщение пропускается (считается дубликатом) – обычно это выражается в том, что обработчик вообще не вызывается, а сообщение сразу `XACK`-ается как обработанное. Если идентификатора нет в памяти, он туда добавляется и сообщение обрабатывается нормально.
  - Преимущество: очень быстрый доступ (память), простота.
  - Недостаток: каждая нода хранит только то, что сама обработала. В распределённой системе, где несколько процессов rotif параллельно, дубликат может попасть на другой процесс и там не будет отмечен. Также при перезапуске приложения память очищается, и защита от повторов для ранее обработанных сообщений теряется.
- **Redis-based (глобальная)**: При `dedupStore: "redis"` библиотека будет сохранять идентификаторы обработанных сообщений в Redis (например, в ключ-множестве `rotif:dedup:<event>`). Это даёт глянцевое хранилище, разделяемое всеми инстансами:
  - Когда сообщение обрабатывается успешно впервые, его ID добавляется в множество в Redis.
  - При получении нового сообщения каждый подписчик проверяет в Redis, есть ли такой ID. Если есть – сообщение считается уже обработанным ранее (возможно, другим инстансом) и пропускается (ack без вызова handler).
  - Если нет – ID добавляется и выполняется обработка.
  - Такая схема позволяет достичь *глобальной* дедупликации: даже если сообщение по каким-то причинам было доставлено дважды (например, publisher дважды добавил аналогичное сообщение или произошёл failover), все инстансы проверяют единое хранилище и вторую попытку отсеют.
  - Минусы: добавляется дополнительная нагрузка на Redis (одна операция чтения и одна записи в Redis на каждое сообщение). Также нужно ограничивать рост этого хранилища, поэтому и вводится TTL: по истечении TTL запись об обработке стирается и то же сообщение теоретически снова будет обработано, если вдруг придёт (впрочем, обычно к тому времени дубликаты уже не появятся).
  - Есть тонкость: Redis Stream ID сам по себе уникален (повторно такого не будет), но дедупликация помогает в сценариях ретраев и многократной доставки. Если использовать пользовательский `dedupKey`, то вы сами решаете, что считать дубликатом. Например, key = userId, тогда два события с одним userId будут считаться повтором (актуально, если по ошибке дублируется отправка).

Чтобы использовать дедупликацию, включите её в конфигурации. Например:

```typescript
const manager = new NotificationManager({ dedupStore: 'redis', dedupTTL: 3600 });
```

А при публикации указывайте `dedupKey` для сообщений, если требуется логическая дедупликация. Если `dedupKey` не указан, для Streams по умолчанию используется Stream ID в качестве ключа (достаточно для защиты от повторной обработки при XCLAIM/ретраях). Для Pub/Sub без указанного ключа дедупликация не имеет смысла, т.к. нет ID – библиотека просто не будет ничего делать.

**Пример: дедупликация сообщений**

```typescript
// Включим дедупликацию в памяти для примера
const manager = new NotificationManager({ dedupStore: 'memory' });

// Подписчик на событие
manager.subscribe('inventory.update', (item) => {
  console.log('Обновление остатка товара', item.sku);
  updateInventory(item.sku, item.delta);
}, { group: 'inventoryService' });

// Имитация дубликатов: публикуем два раза одно и то же
await manager.publish('inventory.update', { sku: 'A123', delta: 5 }, { dedupKey: 'A123-5' });
await manager.publish('inventory.update', { sku: 'A123', delta: 5 }, { dedupKey: 'A123-5' });
```

В этом примере второй вызов `publish` имеет тот же `dedupKey`. Библиотека определит, что такое сообщение уже было обработано:
- В режиме `memory` – тот же процесс уже внёс `A123-5` в Set после первого выполнения, и при второй доставке (которая, скорее всего, придёт тому же процессу) определит дубликат и не вызовет обработчик.
- Если бы был режим `redis` – даже если второй publish исполнился на другом сервисе, при доставке подписчик через Redis set обнаружил бы ключ и тоже проигнорировал.
- Таким образом, `updateInventory` вызовется ровно один раз, несмотря на двойную публикацию.

Замечание: **дедупликация в Pub/Sub.** В каналах Pub/Sub нет естественных идентификаторов, поэтому dedup работает только при указании `dedupKey` (и только если вы настроили `dedupStore: 'redis'`, так как `'memory'` в рамках одного процесса бессмысленна для pub/sub, где все дубликаты придут сразу и, скорее всего, обработаются до того, как ключ успеет установиться). Однако, в целом, если вам нужна exactly-once, лучше использовать Streams.

## Хуки (middleware) для расширения функционала

rotif позволяет подключать *middleware*-функции (хуки) на разных этапах обработки сообщений. Это полезно для кросс-секционных задач: логирование, метрики, трассировка, модификация сообщений, централизованная обработка ошибок и т.д.

Существуют следующие точки расширения (хуки):

- **beforePublish(event, message)** – вызывается перед публикацией каждого сообщения. Здесь вы можете, например, добавить общий заголовок, провести валидацию или записать в лог факт отправки. Если эта функция вернёт `false`, сообщение не будет опубликовано (можно использовать для фильтрации событий).
- **afterPublish(event, message, messageId)** – вызывается после успешной отправки сообщения в Redis. `messageId` – идентификатор записи в Stream (или число получателей при Pub/Sub). Этот хук удобен для сбора метрик: например, учитывать количество отправленных событий, время отправки, либо для более подробного логирования (с ID).
- **beforeProcess(event, message, context)** – вызывается непосредственно перед передачей сообщения в пользовательский обработчик (подписчика). Можно использовать для подготовки контекста (например, запуск таймера для измерения длительности обработки, лог «начали обработку messageId» и т.п.). Если вернуть `false`, обработчик пользователя не будет вызван, а сообщение будет считаться *пропущенным* (его всё равно нужно будет ack-нуть или retry-ить – будьте осторожны с таким поведением).
- **afterProcess(event, message, context)** – вызывается после успешной обработки сообщения (т.е. после того, как пользовательский handler отработал без ошибки и сообщение ack-нуто). Тут можно остановить таймер и зафиксировать длительность, залогировать успешную обработку, обновить счётчики и т.д.
- **onError(event, message, context, error)** – вызывается, если пользовательский обработчик выбросил исключение или вернул rejected Promise. Позволяет централизованно обработать ошибки. По умолчанию rotif просто логирует неперехваченную ошибку (чтобы она не была подавлена), а затем запускает механизм повторов/DLQ. Если вы предоставите свою функцию onError, вы можете, например, логировать ошибку в внешнюю систему мониторинга. Если ваша реализация onError вернёт `false`, rotif **не будет выполнять стандартный процесс обработки ошибки** (то есть не будет делать retry и не отправит сообщение в DLQ). Это дает вам полный контроль: например, вы можете решить по типу ошибки не повторять, а сразу отправить в DLQ вручную, или вовсе подавить ошибку. Возвращайте `false` осмотрительно.

Подключение хуков:
- Глобально при создании `NotificationManager` через опции (как было описано в разделе конфигурации, например: `new NotificationManager({ beforePublish: ..., onError: ... })`).
- Локально для конкретной подписки через опции `subscribe` (как показано выше). Например:
  ```typescript
  manager.subscribe('event.name', handler, { 
    group: 'g1',
    beforeProcess: (msg, ctx) => { /* ... */ },
    onError: (msg, ctx, err) => { /* ... */ }
  });
  ```
  Локальные хуки переопределяют глобальные для этого события.

**Пример: логирование через хуки**

```typescript
const manager = new NotificationManager({
  beforePublish: (event, message) => {
    console.debug(`[Publish] ${event}:`, message);
  },
  afterPublish: (event, message, id) => {
    console.debug(`[Published] ${event} -> ID ${id}`);
  },
  beforeProcess: (event, message, ctx) => {
    console.debug(`[Process] ${event} (ID=${ctx.id}, attempt=${ctx.attempt})`);
  },
  afterProcess: (event, message, ctx) => {
    console.debug(`[Processed] ${event} (ID=${ctx.id}) successfully.`);
  },
  onError: (event, message, ctx, error) => {
    console.error(`[Error] ${event} (ID=${ctx.id}, attempt=${ctx.attempt}):`, error);
    // Возврат undefined или true позволяет запустить стандартный retry/DLQ
    // Если вернуть false, то rotif не будет ретраить/класть в DLQ автоматически
  }
});
```

С такими хуками каждый этап прохода сообщения через систему будет залогирован. Вы можете развивать идею: например, измерять время от beforeProcess до afterProcess и сохранять метрику, или в onError различать типы ошибок и делать `return false` только для некоторых (беря управление ретраем на себя). Хуки делают библиотеку более гибкой под ваши требования.

## Статистика подписки

Каждый вызов `subscribe()` возвращает объект **Subscription**, предоставляющий методы для управления подпиской. Один из полезных методов – `stats()`, который выдаёт текущую статистику работы подписки.

Вы можете вызвать `Subscription.stats()` в любой момент (например, по таймеру или при получении сигнала) для получения информации:
- **`event`** – имя события, на которое выполнена подписка.
- **`mode`** – режим подписки: `"stream"` или `"pubsub"`.
- **`group`** – название группы (если Streams), либо `null` для Pub/Sub.
- **`consumer`** – имя consumer-а (для Streams) или `null` для Pub/Sub.
- **`connected`** – состояние подключения (например, `true` если подписка активна; `false` если была отписка или потеря соединения).
- **`received`** – общее количество сообщений, полученных подпиской (включая успешно обработанные, в процессе и дубли).
- **`processed`** – количество сообщений, успешно обработанных и подтверждённых.
- **`failed`** – число сообщений, обработка которых завершилась ошибкой (и потребовался ретрай или уход в DLQ).
- **`retries`** – сколько раз в сумме происходили повторы для сообщений данной подписки.
- **`pending`** – (для Streams) текущее количество сообщений в статусе *pending* у данной группы (возможно с разбивкой по consumer-ам, если несколько). Это те сообщения, которые были доставлены, но еще не подтверждены. Например, если обработчик завис или работает очень медленно, pending может быть > 0. В Pub/Sub такой метрики нет.
- **`lastMessageId`** – идентификатор последнего обработанного сообщения (Streams) или отметка времени последнего сообщения (Pub/Sub).
- **`uptime`** – время в миллисекундах с момента запуска подписки.
- Возможно, другие поля (в зависимости от версии библиотеки, статистика может расширяться).

**Пример использования `stats()`:**

```typescript
const sub = manager.subscribe('trade.executed', onTrade, { group: 'trades' });
// ... спустя некоторое время
const stats = sub.stats();
console.log('Статистика подписки:', stats);
```

Вы можете периодически выводить или отправлять эту статистику в monitoring. Например, `processed` и `failed` помогут понять, сколько сообщений успешно обработано, а сколько упало, `pending` – признак, нет ли "зависших" сообщений, `retries` – индикатор нагрузки на механизм повторов.

Также объект Subscription позволяет отписаться: `sub.unsubscribe()`. При отписке соединения (блокирующее чтение Streams или подписка на канал) будут закрыты корректно.

## Эксплуатация и масштабирование

При использовании rotif в реальном проекте важно понимать некоторые аспекты, связанные с Redis и общим масштабированием системы. В этом разделе – рекомендации и описание поведения в продакшене, в том числе при кластерной установке, отказах и росте нагрузки.

### Использование Redis Streams в продакшене

Redis Streams – мощный механизм, обеспечивающий надежную очередь сообщений. Чтобы эффективно применять его, учтите следующее:

- **Команды, используемые библиотекой:** rotif под капотом использует следующие команды Redis:
  - `XADD` – для добавления новых сообщений в поток (при вызове `publish` в режиме Streams). В продакшене стоит подумать об ограничении роста стримов: вы можете настроить `maxStreamLength` (как описано выше) или периодически вызывать `XTRIM` для старых сообщений.
  - `XGROUP CREATE` – для создания групп потребителей (выполняется один раз при первой подписке с новым именем группы). Используется с опцией `MKSTREAM` (если поток не существует, он будет создан).
  - `XREADGROUP` – для чтения новых сообщений группой. Библиотека обычно вызывает `XREADGROUP GROUP groupName consumerName STREAMS streamName id` где `id` — либо `>` (для блокирующего чтения новых сообщений), либо конкретный ID (например, `0` или другое, если нужно читать историю).
    * Блокирующий режим: rotif использует `BLOCK` с таймаутом (например, 1-5 секунд) или без таймаута, чтобы долго удерживать соединение, ожидая новые данные. Это обеспечивает малую задержку доставки без активного опроса.
  - `XACK` – подтверждение обработки. Вызывается автоматически после выполнения обработчика (если не включен manualAck).
  - `XDEL` – явное удаление сообщений из стрима. **rotif по умолчанию не удаляет сообщения из потока после XACK**, так как может быть несколько групп (другие группы еще не прочитали это сообщение). Но если вы уверены, что используете только одну группу (или не храните долгий backlog), вы можете самостоятельно время от времени чистить поток. Либо, если у вас одна группа, можно настроить опцию, чтобы после XACK вызывать XDEL (в текущей версии такого флага может не быть, но возможно появится).
  - `XPENDING` / `XINFO` – служебные команды, используемые для диагностики и статистики. Например, `stats()` вызывает `XINFO GROUPS` или `XPENDING` чтобы узнать число pending сообщений и др.
  - `XCLAIM` / `XAUTOCLAIM` – используются для реализации retry. `XAUTOCLAIM` (с Redis 6.2) позволяет получить сообщение из pending, если оно висит более N миллисекунд, и перевести его на текущего consumer-а. Если Redis версии 6.2+, rotif использует XAUTOCLAIM (более эффективно, может сразу несколько сообщений вернуть). Если версия 5.0–6.0, используется XCLAIM для одного сообщения за раз.
  - `ZADD` / `ZPOPMIN` – используются для отложенных сообщений (добавление в отсортированное множество и выборка самых ранних для доставки).
- **Ограничение длины стрима:** если вы не будете удалять или обрезать старые сообщения, Redis Stream может расти бесконечно, занимая память. Для постоянно генерируемых событий настройте политику очистки:
  - Вариант 1: `maxStreamLength` (approx trimming) – при каждом XADD Redis сам будет удалять старые записи свыше заданного. Это очень удобно, но учтите: *точное* обрезание (без ~) может блокировать Redis на длительное время при большом объёме, лучше использовать approximate (`~`).
  - Вариант 2: Использовать TTL на ключ стрима через вызов `EXPIRE`. Однако это удалит **весь** стрим спустя время, так что не подходит, если он постоянно используется.
  - Вариант 3: Периодически (например, раз в сутки) переноси старые сообщения в архив (другой ключ) или просто удалять, если они не нужны. Можно через `XTRIM` или `XDEL` по диапазону ID.
  - Если у вас несколько групп, подумайте, все ли они успевают читать до удаления. У каждого стрима есть параметр `last_delivered_id` для каждой группы – удалять записи старше самого малого из этих ID безопасно (все группы их уже получили).
- **Производительность:** Redis Streams довольно эффективны, но при очень высокой нагрузке (десятки тысяч сообщений в секунду) следите за:
  - Задержкой команд XREADGROUP (в больших стримах поиск следующего сообщения может занимать время, хотя Redis оптимизирован для последовательного чтения).
  - Накоплением pending-листа: если потребители не успевают, `XPENDING` может расти. Это сигнал либо увеличить число потребителей (горизонтально), либо поток обработки (оптимизировать handler), либо разбить событие на несколько стримов.
  - **Триммирование**: помогает держать размер стрима в узде, но если retention слишком мал, риск, что медленные потребители не успеют получить сообщения до удаления.

В целом, Streams подходят для продакшена при соблюдении этих мер. Их плюс – надежность, минус – чуть большая сложность в управлении (в сравнении с Pub/Sub).

### Поддержка Redis Cluster

rotif может работать с Redis Cluster. Есть несколько особенностей и ограничений при этом:
- **Подключение:** используйте либо клиент `ioredis`, который автоматически работает с кластером (передав его через `redisOptions`/`client`), либо node-redis v4 с настройкой cluster. Вы можете указать несколько URL узлов (например, `redisUrls: ['redis://host1:6379', 'redis://host2:6379']`) – тогда библиотека попытается соединиться к кластеру. В противном случае, указав один `redisUrl`, вы подключитесь только к одному узлу. Так как rotif использует стандартные команды, Redis Cluster сам перенаправит их на нужные шарды в зависимости от ключей.
- **Ключи и хеш-слоты:** Имя события (`event`) используется как ключ для Redis Stream и/или канала. В Redis Cluster каждый ключ принадлежит опредёлённому shard по алгоритму хеширования. Важный момент – **команды с несколькими ключами** (например, `XREADGROUP` может читать с нескольких стримов сразу, или `XINFO` для разных ключей) работают только если все ключи на одном шарде (в одном slot). В текущей версии rotif каждая подписка оперирует одним стримом, поэтому проблемы multi-key обычно нет. Но если бы вы использовали, скажем, `manager.subscribe(['ev1','ev2'], ...)` (в этой версии, кажется, нет такого – подписываемся по одному), то не гарантировано, что `ev1` и `ev2` в одном слоте и Redis бы выдал *CROSSSLOT* ошибку. Поэтому:
  - Старайтесь избегать общих операций над разными событиями в одном вызове.
  - Если очень нужно сгруппировать события, используйте ключевые теги Redis: например, названия `event1-{proj}`, `event2-{proj}` – тогда часть в `{}` игнорируется при хешировании и оба ключа будут на одном слоте.
- **Pub/Sub в кластере:** Обычный (глобальный) Pub/Sub в Redis Cluster работает, но с оговорками: команда `PUBLISH` отправляется на конкретный узел по хешу канала, а потом Redis распространяет сообщение по внутренней шине на все узлы. То есть подписчик, подключенный к любому узлу, получит сообщение. Однако, это может стать узким местом при очень большом трафике (каждое сообщение распространяется на весь кластер). Redis 7.0 ввёл **Sharded Pub/Sub** (команды SSUBSCRIBE/SPUBLISH), где сообщение остается в пределах одного shard – но rotif пока не использует эти команды. Поэтому, при использовании Pub/Sub на кластере:
  - Если у вас тысячи сообщений в секунду по каналам, будьте готовы к нагрузке на кластерную шину. Можно рассмотреть sharded pubsub (но придётся самостоятельно использовать ioredis и методы).
  - Все подписчики через rotif в режиме pubsub подключаются к одному узлу (вероятно тому, что в `redisUrl`). Это означает, если узел кластера упадет, подписки прервутся (независимо от того, есть другие узлы). Решение: либо на уровне клиента обеспечить автоматический перескок подписки на другой узел, либо использовать несколько `NotificationManager` к разным узлам. В целом, Streams надёжнее в кластере, т.к. *consumer group* привязан к ключу на конкретном shard, и при падении узла Redis Cluster сам выполнит failover (переключит на реплику) и вы продолжите работу.
- **Число потоков и шардов:** Можно распределять события по разным узлам, просто выбирая имена так, чтобы они хешировались в разные слоты. Это может повысить пропускную способность (разные стримы пишутся/читаются разными узлами параллельно). Но обычно узкое место – не запись стрима, а обработка или сеть, так что это делается по необходимости.
- **Итог:** rotif поддерживает кластерный режим, но для критичных систем тестируйте сценарии перетасовки слотов и отказа узлов. Библиотека полагается на клиента Redis для обработки MOVED/ASK ответов. Также учитывайте, что `XAUTOCLAIM`/`XCLAIM` должны вызываться на мастере; если в кластере произошёл failover, старый consumer может пытаться claim на уже реплику – node-redis/ioredis должны автоматически направлять команду мастеру.

### Поведение при сбоях

Рассмотрим, как ведёт себя система при различных проблемных ситуациях:

- **Недоступен Redis сервер:** Если соединение с Redis разорвалось (сервер упал или сеть недоступна), то:
  - Все операции публикации будут либо ждать восстановления соединения, либо выбрасывать ошибки (зависит от настроек клиента Redis; по умолчанию node-redis будет пытаться переподключаться автоматически). Ваша программа может получить исключение при вызове `publish` (если клиент настроен не буферизовать или истек таймаут). Рекомендуется обрабатывать такие ошибки: например, ставить сообщения во временный буфер/очередь в памяти и пытаться отправить позже.
  - Подписки Streams (XREADGROUP) и Pub/Sub, выполняемые блокирующим образом, обнаружат разрыв соединения. rotif настроен автоматически переподписываться: т.е. после восстановления связи он вновь выполнит `XREADGROUP` или `SUBSCRIBE` с последней известной позиции. Для Streams это означает, что messages, которые были добавлены во время недоступности Redis, будут получены (если группа существовала – они просто ждали). Для Pub/Sub – сообщения, отправленные во время простоя, потеряны.
  - В период недоступности Redis новые сообщения, публикуемые с `delayMs`/`deliverAt`, будут поставлены в локальную очередь (возможно, клиент node-redis их буферизует). Но если Redis не вернётся, они могут быть потеряны. Лучше в критичных системах при потере Redis переключаться на резервный или сигнализировать о проблеме.
- **Падение/рестарт потребителя:** Если приложение или процесс, выполняющий `subscribe`, неожиданно завершается:
  - **Streams:** Все сообщения, которые были выданы этому consumer-у и ещё не подтверждены (`XACK`), останутся в Pending. Они не пропадут, потому что хранятся в Redis. Однако без вмешательства они и не будут обработаны, т.к. помечены за конкретным consumer (который уже не существует). Чтобы не потерять их, другие активные потребители в группе должны их "забрать". Здесь вступает механизм **зомби-консюмеров**: rotif периодически проверяет pending сообщения с истекшим временем (больше `retryDelay`) и осуществляет `XCLAIM/XAUTOCLAIM` на них в контексте активного consumer-а. Таким образом, если один из экземпляров упал, через интервал retry его незавершённые сообщения перейдут к работающему экземпляру и будут обработаны повторно. Это и есть тот же механизм retry.
    - Если же все экземпляры группы упали (т.е. некому забирать), сообщения останутся pending до запуска хотя бы одного подписчика. Когда вы перезапустите подписчика с тем же именем consumer или с новым именем, rotif при старте выполнит `XAUTOCLAIM` всех старых (idle) сообщений на себя и начнёт их обрабатывать. Поэтому, после простоя, первые полученные сообщения могут быть "старые", которые не были завершены ранее.
    - В случае, когда consumer упал **после** успешной обработки, но до того как успел отправить XACK (например, приложение упало между обработкой и подтверждением) – Redis не знает, что обработка была успешной. Такое сообщение тоже будет переназначено как не обработанное. Здесь дедупликация спасает: второй раз выполнив обработчик, вы можете понять, что это дубликат (например, операция уже выполнена, скажем платеж проведен) и просто проигнорировать. Поэтому для критически важных эффектов (внешних действий) – всегда делайте их идемпотентными или используйте dedupKey.
  - **Pub/Sub:** Если подписчик (consumer) упал, все сообщения, которые публиковались во время его отсутствия, потеряны для него (другие подписчики, если были, получили). Когда он перезапустится и подпишется заново, он будет получать только новые сообщения. Поэтому сбоев подписчика Pub/Sub лучше не допускать в ответственных системах, либо делать так, чтобы сообщения не являлись критичными.
- **Накопление "зависших" сообщений (зомби-консюмер):** Зомби-консюмер – это consumer, который давно не активен, но в pending висит множество сообщений за ним. Такое может случиться, если:
  - Либо у вашего обработчика произошёл deadlock/зависание и он перестал обрабатывать, но соединение не закрылось. Тогда Redis считает consumer живым, но он ничего не подтверждает. Другие в группе не заберут pending, потому что формально consumer активен. Для таких случаев реализуйте таймауты в обработке или используйте `manualAck` с внешним контролем, но это сложно. Проще: наблюдайте за метрикой `pending`. Если она растёт а `processed` нет – значит потребитель завис.
  - Либо consumer завершился не закрыв соединение (например, kill -9, и Redis ещё не понял что соединение мертво). Redis поймёт это через какое-то время tcp-timeout и тогда можно будет claim. Обычно `retryDelay` ставят больше, чем такой таймаут, чтобы XAUTOCLAIM не случился раньше времени.
  - rotif старается решить проблему: при каждой итерации чтения он может вызывать `XAUTOCLAIM` для сообщений старше `retryDelay` * 2 (например). Это гарантирует, что даже если consumer просто не ack, через какое-то время сообщения будут выданы другому. Но будьте внимательны: если обработка долгую время занимает (легально, например обработчик обрабатывает 1 сообщение 1 минуту), нужно увеличить `retryDelay` соответственно, иначе rotif подумает, что сообщение зависло, и передаст его другому, в итоге параллельно два обработчика могут работать над одним – нехорошо. Поэтому настраивайте `retryDelay` >= максимального времени обработки или используйте manualAck, совершая ack только когда точно закончили (при этом отключив авто-ретраи).
- **Повторная доставка того же сообщения несколько раз одновременно:** такого не должно случиться при корректных настройках, но, как описано, возможно если неправильно выбран timeout. Дедупликация поможет смягчить эффект.

Резюме: Streams+Groups в сочетании с ретраями предоставляют достаточно устойчивую к сбоям систему, если правильно настроить интервалы и следить за метриками. Pub/Sub прост, но не даёт защиты – используйте его там, где сообщения не критично потерять.

### Лучшая практика: группы, консюмеры и горизонтальное масштабирование

rotif изначально спроектирован для горизонтального масштабирования – вы можете запустить несколько экземпляров сервиса, и они будут разделять нагрузку по обработке сообщений.

**Группы vs отдельные стримы:**  
- Если два независимых сервиса должны получать все события определённого типа (каждый в своих целях) – используйте **разные группы** на одном стриме. Пример: событие `"user.registered"` должно обработать сервис A (отправить приветственное письмо) и сервис B (начислить бонусы). Можно завести стрим `"user.registered"`, группу `"mailService"` и группу `"bonusService"`. Тогда каждое событие будет помещено в один стрим, но читаться в рамках разных групп (каждая со своей позицией и pending). Таким образом, оба сервиса получат каждое сообщение, но друг другу не мешают.
- Если два или более экземпляров **одного сервиса** должны *разделять* обработку событий – используйте **одну группу** и несколько consumer-ов. Например, у нас 3 копии сервиса A (в трех контейнерах). Они все подписываются на `"user.registered"` с одной группой `"mailService"`, но с разными именами consumer (можно задать через ENV hostname). Тогда Redis будет балансировать сообщения между ними (как на диаграмме выше: 1 -> C1, 2 -> C2...). Это и есть конкурирующие потребители, увеличивающие throughput.
- Не рекомендуется создавать отдельный стрим на каждую копию сервиса – иначе они не будут делить сообщения, каждый будет иметь свой стрим с полным набором событий, что не то, что нужно, плюс больше ключей.
- **Pub/Sub** по сути аналогичен: все подписчики на канал получают все сообщения (что похоже на «каждый со своей группой» для Streams). Но в Pub/Sub нельзя сделать конкурирующих потребителей – если вам надо разделять нагрузку, придётся как-то самостоятельно координировать (обычно это решают не Pub/Sub, а очередью). Поэтому для load balancing лучше Streams.

**Именование групп и consumer-ов:**  
- Дайте группам понятные имена, связанные с логикой сервиса или задачей. Например, `"orderService"`, `"billing"`, `"notifications"`.
- Consumer name (имя экземпляра) может выбираться автоматически, но вы можете задать его вручную для удобства мониторинга. Хороший вариант – включить hostname или идентификатор процесса: `"orderService-<hostname>-<pid>"`. Максимальная длина имени – consumer group имя/consumer имя в Redis ограничено 64 байт, так что не делайте очень длинными.
- Если вы деплоите новую версию сервиса, сохраняйте ту же group, иначе получите две конкурирующие группы и каждое событие начнёт дублироваться (в каждой группе). Если вам нужно так (например, плавный запуск нового сервиса параллельно старому), то учтите, что старые сообщения из стрима новая группа не увидит (если создана с `$`), либо увидит все (если с `0`). Обычно это не требуется – проще разделять события на уровне имен.
- **Количество групп:** Redis Streams легко держат десятки групп на один стрим. Но тысячи – могут начать сказываться на скорости XADD (каждая группа хранит last_id и pending). Не злоупотребляйте: если вам кажется, что нужна группа на каждого пользователя, значит, возможно, стоит использовать другой механизм (напр. отдельные стримы или вовсе Sorted Set).
- **Horizontal scaling:** Масштабирование достигается запуском дополнительных потребителей:
  - При росте входящего потока сообщений, если один процесс не справляется, поднимите второй с той же группой. Они будут параллельно обрабатывать вдвое больше. Аналогично третий, четвертый и т.д. Обычно масштабируется почти линейно, пока Redis не станет узким местом или сам handler (например, внешний API).
  - Масштабировать **отправителей** (publish) просто – любая часть кода может публиковать в стрим, Redis справится, хотя при экстремальной нагрузке 1 стрим/группа упрётся в один поток выполнения на Redis. В кластере можно распределять по shard'ам, как сказано выше.
  - **Внимание:** следите за метриками. Если даже после добавления consumer-ов pending постоянно растёт, значит скорость прихода > скорости обработки. Надо или ещё увеличить потребителей, или отложить часть задач, или увеличить мощность машин.

**Можно ли использовать Pub/Sub в продакшене?**  
Это часто задаваемый вопрос, вынесем его отдельно (ещё раз): да, Pub/Sub можно использовать, но помните:
- Нет гарантии доставки – если ваш подписчик не успел или был отключен, данные ушли.
- Нет очереди, распределения нагрузки – каждый подписчик получает всё.
- Зато latency минимальна, и нет накладных расходов на хранение/подтверждение.
- Практический совет: применяйте Pub/Sub для некритичных вещей: уведомления в UI (например, прогресс задачи, где потеря одного обновления некритична), обновление кэша (если пропущено – в следующий раз обновится), логирование, метрики. Для всего, что влияет на бизнес-логику (заказы, деньги, состояния) – Streams с подтверждением.
- Ещё вариант: можно комбинировать. Например, Streams использовать внутри системы для надёжности, а Pub/Sub для дублирования важных событий наружу (на WebSocket серверы, и т.п., где тоже нет смысла гарантировать, если клиент ушёл).

## FAQ / Часто задаваемые вопросы

**Q: Почему сообщения не доставляются подписчикам?**  
**A:** Возможны несколько причин:
- Убедитесь, что подписка выполнена на точно тот же `event` (название), что используется при публикации. Опечатки или несовпадение имен каналов – самая частая проблема.
- Если вы публикуете без указания `delay`/`deliverAt`, а подписчик настроен через Pub/Sub, то подписчик должен быть запущен *до* публикации. Иначе сообщение некому доставлять и оно теряется. Решение: запускать подписчики раньше отправителей, либо использовать Streams.
- Если используется Streams и группа, а сообщения не приходят: возможно, не была создана группа. rotif создает группу автоматически при подписке; если же вы пытались читать без группы, убедитесь что не используете `{ pubsub: true }` случайно. Также, если группа создана, но вы указали начало чтения с `$`, то сообщения, добавленные *до* момента создания группы, не будут получены (это нормально). Если нужно прочитать старые – создавайте группу с ID `0` (сделать можно вручную в Redis-cli).
- Проверьте соединение с Redis. Если подписчик не подключён (например, Redis недоступен), конечно, он не получит ничего. В `Subscription.stats()` флаг `connected` покажет статус.
- Сообщения могли быть отправлены в DLQ сразу, минуя обработчик (в случае, если dedup посчитал их дубликатами или другие экстремальные случаи). Посмотрите, нет ли данных в DLQ-потоке.
- Наконец, если вы используете Redis Cluster и подписка/публикация идут на разные узлы (разные hash-slot), может быть ситуация, что подписчик слушает один узел, а publish ушел на другой (для Pub/Sub). Для Streams это неважно, Redis перенаправит внутри к правильному, но pub/sub может требовать подключение ко всем узлам или использование `SPUBLISH/SSUBSCRIBE` для шардинга. Решение: либо подключаться через не-кластерный endpoint (например, через Twemproxy, который не поддерживает pubsub? или через Sentinel?), либо избегать pubsub в кластере, либо знать узел ключа. Проще – использовать Streams.

**Q: Как работает механизм retry?**  
**A:** При ошибке в обработчике подписчика (только Streams) сообщение остаётся необработанным и попадает в Pending. rotif отслеживает время, прошедшее с момента, когда сообщение стало pending. Когда проходит интервал `retryDelay` (или первый элемент из массива `retryAttempts`), библиотека с помощью команды Redis `XAUTOCLAIM` забирает сообщение из pending и снова ставит его в очередь на обработку. Поле `attempt` увеличивается. Это повторяется, пока количество попыток не превысит лимит. Между попытками всегда есть пауза – *сообщение не будет доставлено раньше, чем истечёт заданная задержка*. Если все попытки исчерпаны, сообщение отправляется в DLQ. Если в какой-то момент сообщение обработалось успешно, оно `XACK` подтверждается и удаляется из pending, на этом цикл завершается. Важный момент: если приложение перезапустилось, оно при старте сделает `XAUTOCLAIM` всех сообщений, чей *idle time* больше, чем порог (retryDelay), поэтому они тоже будут повторно обработаны. В совокупности это даёт поведение, близкое к традиционным системам очередей с повторными попытками.

**Q: Как диагностировать "зависшие" сообщения в стриме?**  
**A:** "Зависшими" обычно называют сообщения, которые находятся в pending слишком долго и не перераспределяются. Для диагностики:
- Используйте команду `XPENDING <stream> <group>` через redis-cli. Она покажет диапазон ID в pending и количество сообщений, а с опцией `<start> <end> <count>` можно получить конкретные ID и какой consumer держит. Если видите, что есть много pending, привязанных к consumer, который уже не активен – это и есть зомби. Также `XINFO CONSUMERS <stream> <group>` покажет потребителей и сколько у каждого pending.
- В `Subscription.stats()` поле `pending` и, возможно, детали pending (если библиотека предоставляет) могут подсказать ситуацию. Если pending не 0 и не уменьшается – значит какие-то сообщения не подтверждаются.
- rotif автоматически должен re-claim таких зомби сообщения, но если этого не происходит, убедитесь, что `retryAttempts` не 0 и что `retryDelay` адекватен. Возможно, сообщения висят меньше, чем `retryDelay`, и ещё не считаются затянутыми (тогда всё ок). Если же висят дольше `retryDelay*2` – что-то не так: либо onError возвращает false и отключил ретраи, либо процесс, который должен забирать, не работает.
- Вы можете вручную вызвать (с осторожностью) метод `subscription.reclaimPending()` если он есть (или через redis-cli `XAUTOCLAIM`) указав время поменьше, чтобы забрать все зависшие сообщения. После этого они пойдут на retry.
- Лучше заранее проектировать, чтобы таких ситуаций не было: настраивать правильный `retryDelay` (больше максимального времени обработки + запас), следить за consumer-ами.

**Q: Можно ли использовать Pub/Sub в production?**  
**A:** Да, но учитывайте ограничения. Pub/Sub в Redis обеспечивает очень быструю доставку, однако:
- Доставка **не гарантируется**: если получателя нет онлайн, сообщение не сохранится.
- Семантика **at-most-once**: сообщение либо дойдет один раз, либо не дойдет вовсе (например, при сбое).
- Нет автоматических ретраев и очереди ожидания. Если обработка упала, система никак это не узнает.
- Поэтому Pub/Sub годится для не критичных уведомлений (см. выше). Например, транслировать состояние, отправлять события для real-time обновления интерфейса – нормально. Использовать его для межсервисной коммуникации, где важна надежность, не рекомендуется.
- В продакшене часто делают так: критичные вещи – через Streams, а поверх, если нужно мгновенное оповещение, дублируют Pub/Sub. Также, если у вас очень высоконагруженная система, и Kafka/RabbitMQ избыточны, Redis Streams могут заменить их, а Pub/Sub – заменить многоканальные broadcast, но все же знайте риски.
- **Вывод:** использовать Pub/Sub можно, но помните о резервном плане: например, если вы рассылали уведомления пользователей через Pub/Sub и какой-то выпал, хорошо бы иметь периодический консистентный процесс, который проверит, что все получили (или клиент сам запросит на сервере, если пропустил). Ничто не мешает комбинировать: отправили pubsub для скорости и стрим для надежности параллельно.

## Вклад и структура проекта

Мы приветствуем вклад сообщества в развитие rotif! Проект открыт исходным кодом, и вы можете найти репозиторий на GitHub (ссылка указана в package.json). 

**Структура проекта:**
- **`src/`** – исходники библиотеки (на TypeScript). Внутри находятся основные модули:
  - `NotificationManager.ts` – основной класс, описанный выше.
  - `Subscription.ts` – класс, реализующий подписку (то, что возвращается из `subscribe`).
  - Другие файлы: `RedisClient.ts` (обёртка над подключением Redis), `ScheduledMessages.ts` (логика отложенных сообщений), `Deduplication.ts` (реализация дедуп хранилища), и т.д. Код организован по функциональным частям.
- **`test/`** – модульные тесты и интеграционные тесты. Там вы найдёте сценарии, проверяющие отправку/получение сообщений, ретраи, дедупликацию, и пр. (запускаются через `npm test`).
- **`examples/`** – примеры использования (если присутствуют). Можно посмотреть простейшие примеры, демонстрирующие подключение и различные режимы работы.
- **`dist/`** – собираемый выход (при сборке через tsc или bundler) – здесь формируется компилированный JS, распространяемый на npm.
- **Конфигурационные файлы**:
  - `tsconfig.json` – конфигурация TypeScript (целевой уровень ES, включение деклараций, модуль CommonJS/ESM).
  - `.eslintrc`, `.prettierrc` (если есть) – настройки линтера/форматирования кода.
  - `package.json` – содержит скрипты (например, `build`, `test`), зависимости (node-redis) и информацию о версии.
- **Документация** – README (данный файл) содержит основную документацию. Дополнительные сведения (например, CHANGELOG.md с описанием изменений версий, CONTRIBUTING.md с правилами вклада) также присутствуют, если вы хотите поучаствовать.

Чтобы внести вклад:
1. Форкните репозиторий на GitHub, создайте ветку для своей фичи или исправления.
2. Убедитесь, что ваш код покрыт тестами. Добавьте тесты в `test/` на новый функционал либо регрессионные на исправленный баг.
3. Запустите `npm run lint` и `npm test` – все тесты должны проходить, код соответствовать стилю.
4. Создайте Pull Request с описанием ваших изменений. Мейнтейнеры проекта рассмотрят его, дадут обратную связь или примут.
5. Обсуждения ведутся через issues в GitHub – если у вас есть предложения или нашли ошибку, пожалуйста, создайте issue.

Мы стараемся придерживаться семантического версионирования. Любые изменения, ломающие обратную совместимость, будут повышать мажорную версию. Ваш вклад должен соответствовать текущему стилю кодирования и проектирования (SOLID, минимальная зависимость от конкретного клиента Redis и т.п.).

## Лицензия

Проект **rotif** распространяется на условиях лицензии MIT. Вы свободны использовать библиотеку в своих приложениях, изменять исходный код и распространять изменения с соблюдением условий MIT-лицензии. Полный текст лицензии доступен в файле [LICENSE](./LICENSE). Спасибо за использование rotif!